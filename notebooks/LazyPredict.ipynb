{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f6df89",
   "metadata": {},
   "source": [
    "### Não esqueça de entrar na venv específica do lazy predict, obrigatório dado os problemas de compatibilidade do lazy predict com imbalance learn e scikit-learn\n",
    "\n",
    "python3 -m venv venv\n",
    "\n",
    "pip install -r src/lazypredict_requirements.txt\n",
    "\n",
    ". venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70aaf2ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lazypredict.Supervised'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5025/2369817762.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlazypredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupervised\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lazypredict.Supervised'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d62039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correcting_nan(data):\n",
    "  data = data.replace(\"na\", np.nan)\n",
    "  data = data.replace(\"neg\", 0)\n",
    "  data = data.replace(\"pos\", 1)\n",
    "  data = data.apply(pd.to_numeric)\n",
    "  return data\n",
    "\n",
    "def remove_nan_rows_and_columns(data):\n",
    "  column_thresh = data.shape[0]*NAN_COLUMN_THRESHOLD\n",
    "  data = data.dropna(thresh=column_thresh, axis = 1)\n",
    "  row_thresh = data.shape[1]*NAN_ROW_THRESHOLD\n",
    "  data = data.dropna(thresh=row_thresh, axis = 0)\n",
    "  return data\n",
    "\n",
    "def fill_na_with_median(data):\n",
    "  data = data.fillna(data.median())\n",
    "  return data\n",
    "\n",
    "def calculating_corr_matrix(data):\n",
    "  corr = data.corr()\n",
    "  sns.heatmap(corr)\n",
    "  return data, corr\n",
    "\n",
    "def deleting_high_correlation_columns(data, corr):\n",
    "  columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "  for i in range(corr.shape[0]):\n",
    "      for j in range(i+1, corr.shape[0]):\n",
    "          if corr.iloc[i,j] >= CORR_THRESHOLD:\n",
    "              if columns[j]:\n",
    "                  columns[j] = False\n",
    "  selected_columns = data.columns[columns]\n",
    "  data = data[selected_columns]\n",
    "  return data, selected_columns\n",
    "\n",
    "def separate_target_and_features(data):\n",
    "  target = data[label]\n",
    "  features = data.loc[:, data.columns != label]\n",
    "  return target, features\n",
    "\n",
    "def train_test_for_this_dataset(data):\n",
    "    train = data.loc[data['2020'] == 0].loc[:, data.columns != flag_column]\n",
    "    test = data.loc[data['2020'] == 1].loc[:, data.columns != flag_column]\n",
    "    x_train = train.loc[:, train.columns != label]\n",
    "    x_test = test.loc[:, test.columns != label]\n",
    "    y_train = train[label]\n",
    "    y_test = test[label]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing pipeline:\n",
    "\n",
    "data = correcting_nan(data)\n",
    "data = remove_nan_rows_and_columns(data)\n",
    "data = fill_na_with_median(data)\n",
    "data, corr = calculating_corr_matrix(data)\n",
    "data, _ = deleting_high_correlation_columns(data, corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def yeo_johnson(x):\n",
    "    power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "    x = pd.DataFrame(power.fit_transform(x), columns = x.columns)\n",
    "    return x\n",
    "\n",
    "#removing bad columns\n",
    "list_of_columns = ['cd_000', 'as_000', 'au_000', 'ch_000']\n",
    "\n",
    "def removing_bad_columns(x, list_of_columns):\n",
    "    x.drop(list_of_columns, inplace=True, axis=1)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95588434",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls= LazyClassifier(ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = cls.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls= LazyClassifier(ignore_warnings=False, custom_metric=None)\n",
    "df_dict={}\n",
    "\n",
    "for i in range(1,30):\n",
    "    sample = data.sample(frac=0.10)\n",
    "    x_train, x_test, y_train, y_test = train_test_for_this_dataset(sample)\n",
    "    \n",
    "    x_train = yeo_johnson(x_train)\n",
    "    x_test = yeo_johnson(x_test)\n",
    "    x_train = removing_bad_columns(x_train, list_of_columns)\n",
    "    x_test = removing_bad_columns(x_test, list_of_columns)\n",
    "    \n",
    "    # transform the dataset\n",
    "    oversample = SMOTE()\n",
    "    x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "\n",
    "    \n",
    "    models, predictions = cls.fit(x_train, x_test, y_train, y_test)\n",
    "    df_dict[i] = models\n",
    "    print('next run............')\n",
    "    print(' ')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c09e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat((df_dict)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_row_index = df_concat.groupby(df_concat['Model'])\n",
    "df_means = by_row_index.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c021e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.sort_values(by=['Balanced Accuracy'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (defy)",
   "language": "python",
   "name": "kedro_defy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
